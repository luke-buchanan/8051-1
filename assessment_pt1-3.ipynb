{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155f25e9-c9d9-4171-9abd-ba8bfac12536",
   "metadata": {},
   "source": [
    "# MSc Artificial Intelligence — Machine Learning  \n",
    "## Coursework Part 1 (2025/26): Stock Modelling & Prediction\n",
    "\n",
    "**Release:** Thu 25 September 2025 (Week 2) 17:00 (Europe/London)  \n",
    "**Due:** Mon 3 Nov 2025 (Week 8) 09:00  \n",
    "**Feedback by:** Mon 24 Nov 2025  \n",
    "**Weighting:** **50%** of the module mark\n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "Develop a machine-learning pipeline for stock prediction and package it as a Python class `Student`. The goal is to forecast the next-_H_-day cumulative log return (default: horizon _H_=1); so Target is next-_H_-day cumulative log return $y_t = \\log(C_{t+H}/C_t)$. The staff tester will evaluate your model using a leakage-safe, walk-forward procedure. **The tester will use a set of tickers to test your `Student` class by calling your fit and predict methods a few times.**\n",
    "\n",
    "More specifically, you will:\n",
    "\n",
    "1. Design a reproducible ML pipeline via data engineering, feature engineering, model/parameter selection. **You may compute features such as past log-returns, technical indicators inside your class**. Please do not redefine the target.\n",
    "\n",
    "   *Repro notes:* use fixed random seeds; include a `requirements.txt` cell.\n",
    "\n",
    "2. Evaluate the pipeline across a development ticker universe (XLK, XLP, XLV, XLF, XLE, XLI) via time-aware validation (walk-forward / expanding window). **Justify your decisions with experimental evidence or arguments**. Report Directional Accuracy, MAE, RMSE.  \n",
    "   *No leakage:* use only information available up to time *t* to predict *t+_h_* (the tester enforces walk-forward fitting).\n",
    "\n",
    "3. Iterate steps (1)–(2) to select your best pipeline.\n",
    "\n",
    "4. Implement your best pipeline as `Student` exposing `fit(X_train, y_train, meta)` and `predict(X, meta)` (API below).\n",
    "\n",
    "5. Create one Jupyter Notebook that documents your exploration and evidence, and **one Python file that contains your final `Student` class**. Staff will test your class with a tool: `mltester` (ML metrics).\n",
    "\n",
    "## Provided\n",
    "- `mltester.py` — an evaluator that:\n",
    "  - loads per-ticker OHLCV from a long file, `prices.csv`,\n",
    "  - constructs the target \\(y_t\\) for a chosen horizon `H`,\n",
    "  - runs expanding-window walk-forward (re-fit every `step` test days),\n",
    "  - reports Directional Accuracy (DirAcc), MAE, RMSE, and saves per-ticker CSVs + a summary.\n",
    "- Example `student.py` — minimal baseline showing the required API and simple, causal features.\n",
    "- Data — you will prototype with a development universe of tickers and download data from Yahoo Finance; final grading uses a held-out universe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d82533-2ee7-4362-ac8c-67eb40047b6b",
   "metadata": {},
   "source": [
    "## Quick sanity run (**please see comments below**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593212c-34ac-45ac-89ba-9ea9fb6e9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "python mltester.py \\\n",
    "  # Names of your python file and the class\n",
    "  --model ./student.py:Student \\\n",
    "  # Example tickers used in my tests; the actual tickers may be any set of tickers similar to the development tickers.\n",
    "  --tickers SPY TLT GLD \\  \n",
    "  # Use cached CSV to avoid yfinance rate limits if downloads fail. \n",
    "  # this is used to get around Yahoo Finance 'rate limit' warning: if yfinance doesn't work, I will read data from this file.\n",
    "  --data-file data/prices.csv \\ \n",
    "  # Example time window (actual window may be different): I will use data in this time window to train models with your 'fit' method and then test the fitted model with your 'predict' method.\n",
    "  --start 2015-01-01 --end 2019-12-31 \\ \n",
    "  # Walk forward the window: fit/predict horizon=5, then advance by step=10 between fits; repeat this for a few times\n",
    "  # I will call 'fit/prediction' a few times to make predictions with a horizon of e.g. 5 by walking through this window in steps of size e.g. 10\n",
    "  --horizon 5 --step 10 \\ \n",
    "  # Save test results in an output file\n",
    "  --out-dir outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad1ec3-96e2-4cf2-8c4e-b2d65d29a7e7",
   "metadata": {},
   "source": [
    "## Data file (prices.csv) used by the tool  \n",
    "A single long CSV file with columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a54bf-0103-446f-abe7-a40bfb8127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date, ticker, close[, open, high, low, volume, adj_close]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca5410-399b-4581-b591-b8f8138ea1fc",
   "metadata": {},
   "source": [
    "## `Student` API (must match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59e653-816c-4421-b493-111d2ae50004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Student:\n",
    "    def __init__(self, config: dict | None = None, random_state: int = 42):\n",
    "        \"\"\"Store hyperparameters, initialise pipeline objects, set seeds.\"\"\"\n",
    "\n",
    "    def fit(self,\n",
    "            X_train: pd.DataFrame,   # Per-ticker OHLCV indexed by date; includes at least 'Close'\n",
    "            y_train: pd.Series,      # Provided by tester: next-h-day cumulative log return\n",
    "            meta: dict | None = None # e.g., {\"ticker\": \"...\", \"horizon\": h}\n",
    "           ):\n",
    "        \"\"\"Train using only information available up to each training date. Return self.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def predict(self,\n",
    "                X: pd.DataFrame,      # Per-ticker OHLCV up to and including prediction dates\n",
    "                meta: dict | None = None\n",
    "               ) -> pd.Series:\n",
    "        \"\"\"Return a numeric Series named 'y_pred' on the dates where features exist.\"\"\"\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22c6cc-7b2f-439f-acb2-ada0ae2b5105",
   "metadata": {},
   "source": [
    "## How staff will test\n",
    "`mltester.py`: walk-forward evaluation with multiple runs of fit/predict methods. Reports Directional Accuracy, MAE, RMSE. The tool runs on a held-out universe and dates for marking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f1fbc-e2c8-4f8b-8421-4fdff98adaeb",
   "metadata": {},
   "source": [
    "## Assessment rubric (100 marks total)\n",
    "### A. Test results by `mltester`(50)\n",
    "*Assessed on the held-out universe using staff tools.*  \n",
    "**Excellent** (41–50): strong/consistent across tickers; stable.  \n",
    "**Good** (31–40): generally solid; minor instability.  \n",
    "**Adequate** (21–30): modest improvement; fragile/inconsistent.  \n",
    "**Poor** (0–20): little/no signal; erratic or broken outputs.\n",
    "### B. Evaluation depth & ML use (40)\n",
    "**Overall experimental design** (10) — time-aware splits; windows documented; re-fit cadence justified.  \n",
    "**Breadth of exploration** (10) — multiple algorithms/parameters/feature sets; rationale; comparisons to simple baselines.  \n",
    "**Leakage control & validation discipline** (10) — correct fit/transform separation; no peeking; proper alignment.  \n",
    "**Metrics & analysis** (10) — appropriate ML metrics; clear tables/plots; basic robustness (sensitivity to windows/params/seeds).  \n",
    "*Per-criterion bands (out of 10): Excellent (9–10) thorough & well-justified; Good (7–8) solid, minor gaps; Adequate (5–6) basic; Poor (0–4) superficial/incorrect.*  \n",
    "### C. Notebook quality (10)\n",
    "**Reproducibility & clarity** (10) — fixed seeds; requirements.txt cell; how-to-run notes; clear structure/comments; runs cleanly.  \n",
    "*Excellent (9–10) polished/easy to run; Good (7–8) minor rough edges; Adequate (5–6) runs but messy; Poor (0–4) hard to follow or fails to run.*\n",
    "## Penalties & guidance\n",
    "~~Modifying tester rules: runability fail + heavy penalties.~~  \n",
    "Obvious leakage or irreproducible results: up to −30 marks.  \n",
    "Notebook that does not run end-to-end: up to -50 for Section A and up to −4 for Section C.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa070a01-8177-45fc-ab36-44b1e86b3646",
   "metadata": {},
   "source": [
    "## Submission\n",
    "~~Submit one file: ECS8051_CW1_\\<StudentID\\>.ipynb.  \n",
    "No external files required (we will import Student directly from your notebook).  \n",
    "Late penalties as per School policy.~~\n",
    "\n",
    "Submit one Jupyter Notebook file: ECS8051_CW1_\\<StudentID\\>.ipynb to document your development journey, and one Python file `student.py` to present your `Student` class.\n",
    "**Your documentation may be presented as comments in multiple markdown cells alongside code cells, or as a report in a single markdown cell at the end of your notebook. It should include the following:**\n",
    "- **Justification of your decisions**\n",
    "- **Explanation of what you did**\n",
    "- **Presentation of your findings and insights**\n",
    "\n",
    "**You may also include other things that you would like to highlight.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbbd22-637c-4855-9d1c-67716bec276b",
   "metadata": {},
   "source": [
    "## Note on Dataset Choice\n",
    "In this project we use sector ETFs (e.g. Technology, Healthcare, Energy). Each ETF represents a whole industry rather than a single company. This makes the time series:\n",
    "\n",
    "- Cleaner and more stable than individual stocks (less dominated by one-off firm events).\n",
    "- Comparable across sectors, so you can evaluate how your ML pipeline performs under different market behaviours (e.g. cyclical vs defensive sectors).\n",
    "\n",
    "This decision is made for pedagogical purposes: it ensures that you focus on building sound machine learning pipelines and interpreting results across different sectors, rather than being distracted by the excessive noise of individual stocks or the complexity of mixing unrelated asset classes. During marking, your pipelines will be evaluated on a different but parallel set of ETFs to test generalisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a11a8f-8197-4deb-98ec-27265ffcbefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
